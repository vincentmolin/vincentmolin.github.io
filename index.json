[{"content":"The following script generates a \u0026ldquo;maze\u0026rdquo; that satisfies the following condition: there is a single unique path connecting any two points. The \u0026ldquo;maze\u0026rdquo; is actually the minimal spanning tree of a grid graph with random edge weights. We find this tree by starting in an arbitrary point and then greedily add the cheapest visible edge such that we don\u0026rsquo;t form any cycles. This procedure is known as Prim\u0026rsquo;s algorithm.\nimport numpy as np from matplotlib.patches import Circle, Arrow, Rectangle import matplotlib.pyplot as plt # actually creates a rectangular grid graph with random edge-weights # and finds a minimal spanning tree by running Prim\u0026#39;s algorithm def create_maze_graph(width, height): rng = np.random.default_rng() # unique integer weights! (not necessary) edge_weights = rng.permutation(2 * width * height - width - height) # weights for vertical connections V = np.reshape(edge_weights[:width*(height-1)], (height-1, width)) # weights for horizontal connections H = np.reshape(edge_weights[-(width-1)*height:], (height, width-1)) # keep track of visited nodes nodes_visited = np.zeros((height, width)) # start somewhere nodes_visited[0,0] = 1 # let\u0026#39;s count this as well n_nodes_visited = 1 # list of edges currently in consideration visible_edges = [ ((0,0), (0,1), H[0,0]), ((0,0), (1,0), V[0,0])] edges = [] while n_nodes_visited \u0026lt; width*height: # find cheapest visible edge and save it edge = min(visible_edges, key = lambda x : x[2]) edges.append(edge) # where we came from old_node = edge[0] # where we went new_node = edge[1] nodes_visited[new_node] = 1 n_nodes_visited += 1 # remove edges leading in to the new node visible_edges = list(filter(lambda x: x[1] != new_node, visible_edges)) # add new visible edges... row = new_node[0] col = new_node[1] # ...above? if row \u0026gt; 0: if not nodes_visited[(row - 1, col)]: visible_edges.append((new_node, (row - 1, col), V[(row - 1, col)])) # ...under? if row \u0026lt; height - 1: if not nodes_visited[(row + 1, col)]: visible_edges.append((new_node, (row + 1, col), V[(row, col)])) # ...to the left? if col \u0026gt; 0: if not nodes_visited[(row, col - 1)]: visible_edges.append((new_node, (row, col - 1), H[(row, col - 1)])) # ...to the right? if col \u0026lt; width - 1: if not nodes_visited[(row, col + 1)]: visible_edges.append((new_node, (row, col + 1), H[(row, col)])) return edges # draw the maze def plot_maze_graph(width, height, edges, r=0.27): fig = plt.figure(figsize=(20 * width / ( width + height ), 20 * height / ( width + height ))) fig.patch.set_facecolor(\u0026#39;#1d1e20\u0026#39;) ax = fig.add_axes([0, 0, 1, 1], frameon=False, aspect=1.) ax.set_xlim(0, width) ax.set_ylim(0, height) ax.set_axis_off() ax.set_facecolor((0.5,0.5,0.5)) for edge in edges: start = edge[0] end = edge[1] x = min(start[1], end[1]) - r + 0.5 y = min(start[0], end[0]) - r + 0.5 w = abs(start[1] - end[1]) + 2 * r h = abs(start[0] - end[0]) + 2 * r ax.add_patch(Rectangle((x,y), w, h, color=\u0026#39;white\u0026#39;)) plt.show() # and let\u0026#39;s generate one! width = 20 height = 20 edges = create_maze_graph(width, height) plot_maze_graph(width, height, edges) Cool! TODO: Animate\n","permalink":"http://vincentmolin.github.io/posts/maze/","summary":"The following script generates a \u0026ldquo;maze\u0026rdquo; that satisfies the following condition: there is a single unique path connecting any two points. The \u0026ldquo;maze\u0026rdquo; is actually the minimal spanning tree of a grid graph with random edge weights. We find this tree by starting in an arbitrary point and then greedily add the cheapest visible edge such that we don\u0026rsquo;t form any cycles. This procedure is known as Prim\u0026rsquo;s algorithm.\nimport numpy as np from matplotlib.","title":"Generating a maze in Python"},{"content":"import matplotlib.pyplot as plt import numpy as np x = np.array(range(0,10)) y = x ** 2 plt.plot(x,y) plt.show() import pandas as pd df = pd.read_csv(\u0026#39;vacc_train_data.tsv\u0026#39;,sep=\u0026#39;\\t\u0026#39;, names=[\u0026#39;target\u0026#39;,\u0026#39;comment\u0026#39;]) df.head(5) .dataframe tbody tr th {\rvertical-align: top;\r}\r.dataframe thead th {\rtext-align: right;\r}\r ","permalink":"http://vincentmolin.github.io/posts/my-pyplot/","summary":"import matplotlib.pyplot as plt import numpy as np x = np.array(range(0,10)) y = x ** 2 plt.plot(x,y) plt.show() import pandas as pd df = pd.read_csv(\u0026#39;vacc_train_data.tsv\u0026#39;,sep=\u0026#39;\\t\u0026#39;, names=[\u0026#39;target\u0026#39;,\u0026#39;comment\u0026#39;]) df.head(5) .dataframe tbody tr th {\rvertical-align: top;\r}\r.dataframe thead th {\rtext-align: right;\r}\r ","title":"Test: Notebook With Plot and Table"},{"content":"In this series of posts we\u0026rsquo;re going to build a text classification model that predicts whether a comment expresses a negative or positive stance on COVID-19 vaccination. This short first installment will deal with the way in which we digest the raw comments into something a bit more workable before doing any machine-learn-y things.\nCleaning up the comments The data we have on hand are roughly 9,000 scraped comments from various sources such as YouTube, Reddit and Twitter. Each comment has first been labeled individually as either 1 or 0, expressing a positive or negative stance respectively. All comments have after that also independently been labeled by at least one other annotator, as we will see. Let\u0026rsquo;s start up pandas, our data handling package of choice, and inspect some rows!\nimport pandas as pd\r# These comments are pretty long\rpd.set_option('display.max_colwidth', None)\r# Technically not a csv but pandas don't mind\rdf = pd.read_csv('vacc_train_data.tsv', sep='\\t', names=['target','comment'])\rfor row in df.loc[:5,'comment']:\rprint('\u0026quot;' + row + '\u0026quot;\\n')\r\u0026quot; It is easier to fool a million people than it is to convince a million people that they have been fooled. - Mark Twain\u0026quot;\r\u0026quot; NATURAL IMMUNITY protected us since evolution. Do not exist anymore?\u0026quot;\r\u0026quot; NATURAL IMMUNITY protected us since evolution. Do not exist anymore? ? ? No one talks about it, Why? ?\u0026quot;\r\u0026quot; The bigest sideffect of vaccines is fewer dead children That is savage\u0026quot;\r\u0026quot;90% of people that get vaccinated don't get the virus Wooow what's in the vaccine then? I'm very pro vaccination, but in my opinion Covid 19 vaccine is just sweetened water.\u0026quot;\r\u0026quot;95.6% effective against the original strain and 85.6% effective against the variant. Excellent news. Every positive news during this pandemic is to be welcomed (no pun intended)\u0026quot;\r The goal of our preprocessing steps here is to homogenize the text data a bit. We will later in our first model only consider the words in a given sentence, without regarding the order in which they were written. To this end, punctuation becomes very irrelevant so we will just strip it, and we will also make sure that everything is in lower case. Website URLs also seem reasonable to remove.\nEmojis Special characters that however are of interest are emojis. Consider the following three fictitious comments:\n Vaccine = â˜  vaccine ðŸ˜€ ðŸ’‰ðŸ¤®ðŸ¤®  Stripping the emojis from these comments removes pretty important information. Luckily for us, all emojis have descriptions and we can just translate these using the demoji package! We can now write the text cleaning function. We will make use of some regexp-stuff, just roll with the punches if this looks weird.\nimport re, string\rimport demoji\r#demoji.download_codes()\rdef textify_emojis(text):\r# Returns a dictionary with 'emoji' : 'description' pairs\remojis = demoji.findall(text)\r# We have to slightly modify the descriptions\r# by replacing all special characters with dashes\r# and then surrounding them with \u0026quot;:\u0026quot; and whitespace\rfor emoji, desc in emojis.items():\rdesc = ' :'+re.sub(r\u0026quot;[^0-9a-zA-Z]+\u0026quot;, \u0026quot;-\u0026quot;, desc )+': '\rtext = re.sub(emoji, desc, text)\rreturn text\r# Function that returns nice and clean text\rdef clean_text(text):\r# Make all text lowercase\rtext = text.lower()\r# Remove links\rtext = re.sub('https?://\\S+|www\\.\\S+', '', text)\r# Replace newline with space\rtext = re.sub('\\n', ' ', text)\r# Remove all \u0026quot;:\u0026quot; and \u0026quot;-\u0026quot;-characters first, we will # use these to represent emojis\rtext = re.sub(r\u0026quot;[:\\-]\u0026quot;, '', text)\r# Replace emojis with text descriptions\rtext = textify_emojis(text)\r# Remove most non-alphanumerical characters\rtext = re.sub(r\u0026quot;[^0-9a-zA-Z%:\\- ]+\u0026quot;, \u0026quot;\u0026quot;, text)\r# Get rid of unnecessary whitespace\rtext = ' '.join(text.split())\r# Done!\rreturn text text = \u0026quot;ðŸ’‰ðŸ¤®ðŸ¤®\u0026quot;\rprint(text, '---\u0026gt;', '\u0026quot;' + clean_text(text) + '\u0026quot;')\rðŸ’‰ðŸ¤®ðŸ¤® ---\u0026gt; \u0026quot;:syringe: :face-vomiting: :face-vomiting:\u0026quot;\r Nice! Now we apply this to the whole dataset.\ndf['comment'] = df['comment'].apply(lambda x: clean_text(x))\rfor row in df.loc[:5,'comment']:\rprint('\u0026quot;' + row + '\u0026quot;\\n')\r\u0026quot;it is easier to fool a million people than it is to convince a million people that they have been fooled mark twain\u0026quot;\r\u0026quot;natural immunity protected us since evolution do not exist anymore\u0026quot;\r\u0026quot;natural immunity protected us since evolution do not exist anymore no one talks about it why\u0026quot;\r\u0026quot;the bigest sideffect of vaccines is fewer dead children that is savage\u0026quot;\r\u0026quot;90% of people that get vaccinated dont get the virus wooow whats in the vaccine then im very pro vaccination but in my opinion covid 19 vaccine is just sweetened water\u0026quot;\r\u0026quot;956% effective against the original strain and 856% effective against the variant excellent news every positive news during this pandemic is to be welcomed no pun intended\u0026quot;\r Okay, the percentages look a bit wonky, and we didn\u0026rsquo;t see any example with an encoded emoji. Looking at the raw data, row 36 contains a comment with an emoji.\nprint('\u0026quot;' + df.loc[35,'comment'] + '\u0026quot;')\rtrust the government :rolling-on-the-floor-laughing:\r We might do something about the percentages later, but that\u0026rsquo;s all for now!\n","permalink":"http://vincentmolin.github.io/posts/vacc-part1-preprocess/","summary":"In this series of posts we\u0026rsquo;re going to build a text classification model that predicts whether a comment expresses a negative or positive stance on COVID-19 vaccination. This short first installment will deal with the way in which we digest the raw comments into something a bit more workable before doing any machine-learn-y things.\nCleaning up the comments The data we have on hand are roughly 9,000 scraped comments from various sources such as YouTube, Reddit and Twitter.","title":"Sentiment Classification: Preprocessing Part 1"},{"content":"Some year around the time when we started using computers, the 50s or so, someone came up with the idea of the perceptron: the brain-inspired machine that could learn! Even though the author had high hopes for this model, it sadly couldn\u0026rsquo;t learn very much. It is however very easy to implement, so let\u0026rsquo;s do it.\n# Start writing code here...\r","permalink":"http://vincentmolin.github.io/posts/perceptron/","summary":"Some year around the time when we started using computers, the 50s or so, someone came up with the idea of the perceptron: the brain-inspired machine that could learn! Even though the author had high hopes for this model, it sadly couldn\u0026rsquo;t learn very much. It is however very easy to implement, so let\u0026rsquo;s do it.\n# Start writing code here...\r","title":"A simple perceptron"},{"content":"Hej ","permalink":"http://vincentmolin.github.io/about/","summary":"about","title":"About me"}]