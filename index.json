[{"content":"In this series of posts we\u0026rsquo;re going to build a text classification model that predicts whether a comment expresses a negative or positive stance on COVID-19 vaccination. This short first installment will deal with the way in which we digest the raw comments into something a bit more workable before doing any machine-learn-y things.\nCleaning up the comments The data we have on hand are roughly 9,000 scraped comments from various sources such as YouTube, Reddit and Twitter. Each comment has first been labeled individually as either 1 or 0, expressing a positive or negative stance respectively. All comments have after that also independently been labeled by at least one other annotator, as we will see. Let\u0026rsquo;s start up pandas, our data handling package of choice, and inspect some rows!\n\rimport pandas as pd\nThese comments are pretty long pd.set_option(\u0026lsquo;display.max_colwidth\u0026rsquo;, None)\nTechnically not a csv but pandas don\u0026rsquo;t mind df = pd.read_csv(\u0026lsquo;vacc_train_data.tsv\u0026rsquo;, sep='\\t', names=[\u0026lsquo;target\u0026rsquo;,\u0026lsquo;comment\u0026rsquo;])\nfor row in df.loc[:5,\u0026lsquo;comment\u0026rsquo;]: print('\u0026quot;' + row + \u0026lsquo;\u0026quot;\\n\u0026rsquo;)\n\r\u0026quot; It is easier to fool a million people than it is to convince a million people that they have been fooled. - Mark Twain\u0026quot;\r\u0026quot; NATURAL IMMUNITY protected us since evolution. Do not exist anymore?\u0026quot;\r\u0026quot; NATURAL IMMUNITY protected us since evolution. Do not exist anymore? ? ? No one talks about it, Why? ?\u0026quot;\r\u0026quot; The bigest sideffect of vaccines is fewer dead children That is savage\u0026quot;\r\u0026quot;90% of people that get vaccinated don't get the virus Wooow what's in the vaccine then? I'm very pro vaccination, but in my opinion Covid 19 vaccine is just sweetened water.\u0026quot;\r\u0026quot;95.6% effective against the original strain and 85.6% effective against the variant. Excellent news. Every positive news during this pandemic is to be welcomed (no pun intended)\u0026quot;\rThe goal of our preprocessing steps here is to homogenize the text data a bit. We will later in our first model only consider the words in a given sentence, without regarding the order in which they were written. To this end, punctuation becomes very irrelevant so we will just strip it, and we will also make sure that everything is in lower case. Website URLs also seem reasonable to remove.\r### Emojis\rSpecial characters that however are of interest are emojis. Consider the following three fictitious comments:\r1. `Vaccine = â˜ `\r2. `vaccine ðŸ˜€` 3. `ðŸ’‰ðŸ¤®ðŸ¤®`\rStripping the emojis from these comments removes pretty important information.\rLuckily for us, all emojis have descriptions and we can just translate these using the `demoji` package! We can now write the text cleaning function. We will make use of some regexp-stuff, just roll with the punches if this looks weird.\rimport re, string import demoji #demoji.download_codes()\ndef textify_emojis(text): # Returns a dictionary with \u0026lsquo;emoji\u0026rsquo; : \u0026lsquo;description\u0026rsquo; pairs emojis = demoji.findall(text)\n# We have to slightly modify the descriptions\r# by replacing all special characters with dashes\r# and then surrounding them with \u0026quot;:\u0026quot; and whitespace\rfor emoji, desc in emojis.items():\rdesc = ' :'+re.sub(r\u0026quot;[^0-9a-zA-Z]+\u0026quot;, \u0026quot;-\u0026quot;, desc )+': '\rtext = re.sub(emoji, desc, text)\rreturn text\r Function that returns nice and clean text def clean_text(text): # Make all text lowercase text = text.lower()\n# Remove links\rtext = re.sub('https?://\\S+|www\\.\\S+', '', text)\r# Replace newline with space\rtext = re.sub('\\n', ' ', text)\r# Remove all \u0026quot;:\u0026quot; and \u0026quot;-\u0026quot;-characters first, we will # use these to represent emojis\rtext = re.sub(r\u0026quot;[:\\-]\u0026quot;, '', text)\r# Replace emojis with text descriptions\rtext = textify_emojis(text)\r# Remove most non-alphanumerical characters\rtext = re.sub(r\u0026quot;[^0-9a-zA-Z%:\\- ]+\u0026quot;, \u0026quot;\u0026quot;, text)\r# Get rid of unnecessary whitespace\rtext = ' '.join(text.split())\r# Done!\rreturn text  text = \u0026ldquo;ðŸ’‰ðŸ¤®ðŸ¤®\u0026rdquo; print(text, \u0026lsquo;\u0026mdash;\u0026gt;\u0026rsquo;, \u0026lsquo;\u0026quot;\u0026rsquo; + clean_text(text) + \u0026lsquo;\u0026quot;')\n\rðŸ’‰ðŸ¤®ðŸ¤® ---\u0026gt; \u0026quot;:syringe: :face-vomiting: :face-vomiting:\u0026quot;\rNice! Now we apply this to the whole dataset.\rdf[\u0026lsquo;comment\u0026rsquo;] = df[\u0026lsquo;comment\u0026rsquo;].apply(lambda x: clean_text(x))\nfor row in df.loc[:5,\u0026lsquo;comment\u0026rsquo;]: print('\u0026quot;\u0026rsquo; + row + \u0026lsquo;\u0026quot;\\n\u0026rsquo;)\n\r\u0026quot;it is easier to fool a million people than it is to convince a million people that they have been fooled mark twain\u0026quot;\r\u0026quot;natural immunity protected us since evolution do not exist anymore\u0026quot;\r\u0026quot;natural immunity protected us since evolution do not exist anymore no one talks about it why\u0026quot;\r\u0026quot;the bigest sideffect of vaccines is fewer dead children that is savage\u0026quot;\r\u0026quot;90% of people that get vaccinated dont get the virus wooow whats in the vaccine then im very pro vaccination but in my opinion covid 19 vaccine is just sweetened water\u0026quot;\r\u0026quot;956% effective against the original strain and 856% effective against the variant excellent news every positive news during this pandemic is to be welcomed no pun intended\u0026quot;\rOkay, the percentages look a bit wonky, and we didn't see any example with an encoded emoji. Looking at the raw data, row 36 contains a comment with an emoji.\rprint('\u0026quot;' + df.loc[35,\u0026lsquo;comment\u0026rsquo;] + \u0026lsquo;\u0026quot;')\n\rtrust the government :rolling-on-the-floor-laughing:\rWe might do something about the percentages later, but that's all for now! ","permalink":"http://vincentmolin.github.io/posts/vacc-part1-preprocess/","summary":"In this series of posts we\u0026rsquo;re going to build a text classification model that predicts whether a comment expresses a negative or positive stance on COVID-19 vaccination. This short first installment will deal with the way in which we digest the raw comments into something a bit more workable before doing any machine-learn-y things.\nCleaning up the comments The data we have on hand are roughly 9,000 scraped comments from various sources such as YouTube, Reddit and Twitter.","title":"Sentiment Classification: Preprocessing Part 1"},{"content":"Some year around the time when we started using computers, the 50s or so, someone came up with the idea of the perceptron: the brain-inspired machine that could learn! Even though the author had high hopes for this model, it sadly couldn\u0026rsquo;t learn very much. It is however very easy to implement, so let\u0026rsquo;s do it.\n# Start writing code here...\r","permalink":"http://vincentmolin.github.io/posts/perceptron/","summary":"Some year around the time when we started using computers, the 50s or so, someone came up with the idea of the perceptron: the brain-inspired machine that could learn! Even though the author had high hopes for this model, it sadly couldn\u0026rsquo;t learn very much. It is however very easy to implement, so let\u0026rsquo;s do it.\n# Start writing code here...\r","title":"A simple perceptron"},{"content":"Hej ","permalink":"http://vincentmolin.github.io/about/","summary":"about","title":"About me"}]